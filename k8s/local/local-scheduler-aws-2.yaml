---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: ares-local
  namespace: ares-system
  labels:
    app: ares-local
spec:
  selector:
    matchLabels:
      app: ares-local
  template:
    metadata:
      labels:
        app: ares-local
      annotations:
        container.apparmor.security.beta.kubernetes.io/ares-local: "unconfined"
    spec:
      # ✅ NO nodeSelector - runs on all WORKER nodes

      nodeSelector:
        ares.gpu: "true"

      hostNetwork: false
      hostPID: false

      containers:
        - name: ares-local
          image: us-east4-docker.pkg.dev/ares-gpu-test/ares-scheduler/ares-scheduler-local:latest
          imagePullPolicy: Always

          resources:
            requests:
              cpu: "500m"
              memory: "512Mi"
            limits:
              cpu: "2000m"
              memory: "2Gi"

          env:
            - name: ARES_REDIS_ADDR
              value: "34.145.167.199:6379"
#              value: "34.86.13.151:6379"
            - name: ARES_CONTROL_PLANE
              value: "http://35.245.157.53:8080"

            - name: ARES_LOCAL_SCHEDULER_EXTERNAL_ADDR
              value: "http://aa07f14e46b804c35929238eca24a071-1491995129.us-east-1.elb.amazonaws.com:9090"

            - name: WORKER_CLUSTER_ID
              valueFrom:
                configMapKeyRef:
                  name: cluster-config
                  key: cluster-id

            - name: NODE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName

            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name

            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace

            - name: POD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
#            - name: ARES_CLUSTER_ID
#              value: "gke-ares-gpu-worker"

            - name: ARES_REGION
              valueFrom:
                configMapKeyRef:
                  name: cluster-config
                  key: region

            - name: ARES_ZONE
              valueFrom:
                configMapKeyRef:
                  name: cluster-config
                  key: zone

            - name: ARES_K8S_NAMESPACE
              value: "ares-system"

            - name: ARES_LOG_LEVEL
              value: "info"

          ports:
            - name: http
              containerPort: 9090
              protocol: TCP

          livenessProbe:
            httpGet:
              path: /health
              port: 9090
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 3

          readinessProbe:
            httpGet:
              path: /health
              port: 9090
            initialDelaySeconds: 10
            periodSeconds: 5
            timeoutSeconds: 3
            failureThreshold: 3

      serviceAccountName: ares-scheduler

      # ✅ CORRECTED TOLERATIONS (Worker nodes ONLY)
      # These tolerations allow the DaemonSet to run on:
      # - Regular CPU worker nodes (no special taint)
      # - GPU worker nodes (have nvidia.com/gpu taint)
      # - Worker nodes with cloud-provider GPU taints
      # - Worker nodes with custom accelerator taints
      # - Worker nodes with any other custom taints (catch-all)
      #
      # These tolerations DO NOT allow:
      # ❌ Control-plane nodes (no toleration for control-plane taint)
      # ❌ Master nodes (no toleration for master taint)
      tolerations:
        # Tolerate GPU-specific taints (for GPU worker nodes)
        - key: nvidia.com/gpu
          operator: Exists
          effect: NoSchedule
        - key: nvidia.com/gpu
          operator: Exists
          effect: NoExecute

        # Tolerate cloud-provider GPU taints (GCP, AWS, Azure)
        - key: cloud.google.com/gke-accelerator
          operator: Exists
          effect: NoSchedule
        - key: cloud.google.com/gke-accelerator
          operator: Exists
          effect: NoExecute

        # Tolerate generic accelerator taints (some clusters use these)
        - key: accelerator
          operator: Exists
          effect: NoSchedule
        - key: accelerator
          operator: Exists
          effect: NoExecute

        # Catch-all: tolerate any OTHER custom worker node taints
        # This allows the DaemonSet to run on worker nodes
        # with any custom taints not listed above
        - operator: Exists
          effect: NoExecute
        - operator: Exists
          effect: NoSchedule