# Ares + Polaris: Complete Feature Matrix

**Last Updated**: December 2025  
**Total Features**: 26 (22 Ares + 4 Polaris)  
**Completed**: 14/26 

---

## ğŸ“‹ Table of Contents

1. [Feature Categories](#feature-categories)
2. [Ares Features (22)](#ares-features)
    - [Core Scheduling Engine (6 features)](#core-scheduling-engine)
    - [Control Plane Design (6 features)](#control-plane-design)
    - [Resource Awareness (4 features)](#resource-awareness)
    - [Job Execution & Reliability (5 features)](#job-execution--reliability)
    - [Observability & Security (5 features)](#observability--security)
3. [Polaris Features (4)](#polaris-features)
4. [Implementation Roadmap](#implementation-roadmap)
5. [Feature Dependencies](#feature-dependencies)

---

## Feature Categories

```
ARES (22 features)
â”œâ”€â”€ Core Scheduling Engine (6)      - Job placement, fairness, priorities
â”œâ”€â”€ Control Plane Design (6)        - Global coordination, federation
â”œâ”€â”€ Resource Awareness (4)           - GPU, NUMA, network topology
â”œâ”€â”€ Job Execution & Reliability (5) - Lifecycle, retries, exactly-once
â””â”€â”€ Observability & Security (5)    - Metrics, dashboards, RBAC

POLARIS (4 features)                 - Observability platform for Ares
â”œâ”€â”€ Global Metrics Pipeline
â”œâ”€â”€ Unified Dashboard & Tracing
â”œâ”€â”€ Cluster & Job Health Dashboard
â””â”€â”€ Audit Logging & Policy Validation
```
---

## Ares Features

### Core Scheduling Engine

These features handle the core job scheduling logic - where jobs run, how resources are allocated, and prioritization.

---

## Feature Matrix

### Category 1: Core Scheduling Engine

| # | Feature | Description | Status |
|---|--------|-------------|--------|
| 1 | Multi-Cluster Scheduling | Schedule workloads across multiple K8s clusters | **Done** |
| 2 | Multi-Region Federation | Global scheduling across data centers and regions | **Done** |
| 3 | Fair Resource Allocation | DRF / weighted fair queuing to prevent monopolization | Future |
| 4 | Topology-Aware Scheduling | Co-locate by network / rack / zone proximity | **Done** |
| 5 | Priority & Preemption | High-priority jobs preempt lower-priority jobs | Future |
| 6 | Exactly-Once Execution | Distributed leases + fencing tokens | **Done** |

### Category 2: Control Plane Design

| # | Feature | Description | Status |
|---|--------|-------------|--------|
| 7 | Global Control Plane | Central orchestrator coordinating per-cluster schedulers | **Done** |
| 8 | Cluster Autonomy | Local failover when global plane unreachable | Future |
| 9 | Dynamic Cluster Registration | Clusters join/leave dynamically without downtime | **Done** |
|10 | Health & Heartbeat | Health synchronization across clusters | **Done** |
|11 | Eventual Consistency | CRDTs or Raft for critical state | Future |
|12 | API Gateway | Unified global API endpoint for job submission | **Done** |

### Category 3: Resource Awareness

| # | Feature | Description | Status |
|---|--------|-------------|--------|
|13 | GPU-Aware Scheduling | GPU count, model, NVLink topology, NUMA affinity | **Done** |
|14 | NUMA Awareness | Minimize cross-NUMA memory penalties | Future |
|15 | Network Bandwidth Aware | Network latency / bandwidth in scheduling | Future |
|16 | Heterogeneous Hardware | CPUs, GPUs, TPUs, FPGAs, custom accelerators | Future |

### Category 4: Job Execution & Reliability

| # | Feature | Description | Status |
|---|--------|-------------|--------|
|17 | Job Lifecycle Management | Pending â†’ Running â†’ Succeeded / Failed | **Done** |
|18 | Idempotent Submission | Client-side deduplication using request IDs | **Done** |
|19 | Distributed Locking | Lease-based coordination for exactly-once | **Done** |
|20 | Checkpointing | Persist mid-job state for fault recovery | Future |
|21 | Backoff & Retry Policy | Exponential backoff with jitter for failed jobs | Future |

### Category 5: Observability & Security

| # | Feature | Description | Status |
|---|--------|-------------|--------|
|22 | Global Metrics Pipeline | Prometheus / OpenTelemetry metrics federation | Future |
|23 | Unified Dashboard | Grafana dashboards and distributed tracing | Future |
|24 | Health Dashboard | Real-time job latency, failure rates, utilization | Future |
|25 | RBAC + Tenant Isolation | Namespace / tenant quota and access control | Future |
|26 | Audit Logging | Central logging and policy validation | Future |

**Summary:** 12 implemented features Â· 14 planned enhancements



#### #1: Multi-Cluster Scheduling

**Purpose**: Schedule workloads across multiple Kubernetes clusters  
**Complexity**: High  
**Status**: ğŸš§ In Progress (Phase 2)  
**Dependencies**: #7 (Global Control Plane)

**Problem**:
```
Single cluster: Limited to 100 GPUs
Multi-cluster: Scale to 1000+ GPUs across regions
```

**Design**:
- Global job queue (etcd)
- Per-cluster resource tracking
- Cross-cluster placement scoring
- Network latency awareness

**Implementation**:
```go
type ClusterState struct {
    ClusterID   string
    AvailableGPUs int
    Latency     time.Duration
    Load        float64
}

func PlaceJobAcrossClusters(job Job, clusters []ClusterState) string {
    // Score each cluster
    scores := make(map[string]float64)
    for _, cluster := range clusters {
        score := calculateClusterScore(job, cluster)
        scores[cluster.ClusterID] = score
    }
    return chooseBestCluster(scores)
}
```

**Metrics**:
- Cross-cluster placement decisions/sec
- Average job latency per cluster
- Cluster load distribution (fairness)

---

#### #2: Multi-Region Federation

**Purpose**: Global scheduling decisions spanning geographic regions  
**Complexity**: High  
**Status**: â³ Planned (Phase 2)  
**Dependencies**: #1, #7, #8, #9

**Problem**:
```
US-WEST-1: 200 GPUs (high load)
US-EAST-1: 150 GPUs (low load)  
EU-WEST-1: 100 GPUs (idle)

User in US wants to run job â†’ Should schedule in EU?
  - Pro: Faster start (idle capacity)
  - Con: Higher latency, data transfer costs
```

**Design**:
- Global coordinator (Raft consensus)
- Region-aware placement
- Data gravity considerations
- Cost optimization

**Challenges**:
- Network latency between regions (50-150ms)
- Data locality (datasets may be region-locked)
- Regulatory compliance (data residency laws)

---

#### #3: Fair Resource Allocation

**Purpose**: Prevent resource starvation using DRF (Dominant Resource Fairness)  
**Complexity**: Medium  
**Status**: âœ… Complete (MVP)  
**Dependencies**: None

**Problem**:
```
Tenant A: Submits 1000 jobs (starves everyone)
Tenant B: Submits 10 jobs (gets nothing)
Tenant C: Submits 5 jobs (gets nothing)

UNFAIR! 
```

**Solution - Dominant Resource Fairness (DRF)**:
```
Each tenant gets fair share of their "dominant resource"

Tenant A: Dominant = CPUs (uses 80% CPU, 20% GPU)
Tenant B: Dominant = GPUs (uses 30% CPU, 90% GPU)

Allocate to B first (GPU is scarce), then A
```

**Implementation**:
```go
type TenantUsage struct {
    TenantID    string
    CPUShare    float64  // 0.0 - 1.0
    GPUShare    float64  // 0.0 - 1.0
    DominantShare float64 // max(CPUShare, GPUShare)
}

func ScheduleWithDRF(tenants []TenantUsage, job Job) string {
    // Sort by dominant share (ascending)
    sort.Slice(tenants, func(i, j int) bool {
        return tenants[i].DominantShare < tenants[j].DominantShare
    })
    
    // Allocate to tenant with lowest dominant share
    return tenants[0].TenantID
}
```

**Guarantees**:
- **Share guarantee**: Each tenant gets â‰¥ 1/n of resources (n = # tenants)
- **Strategy-proof**: No incentive to lie about requirements
- **Envy-free**: No tenant prefers another's allocation

---

#### #4: Topology-Aware Scheduling

**Purpose**: Co-locate workloads by network/rack/zone proximity + GPU topology  
**Complexity**: Medium-High  
**Status**: âœ… Complete (MVP - basic)  
**Dependencies**: #13 (GPU-Aware Scheduling)

**Problem**:
```
Job needs 8 GPUs

Bad placement:
  GPU-0, GPU-4, GPU-9, GPU-13, GPU-18, GPU-22, GPU-27, GPU-31
  â†’ Spread across 4 nodes, high cross-node traffic

Good placement:
  GPU-0, GPU-1, GPU-2, GPU-3, GPU-4, GPU-5, GPU-6, GPU-7
  â†’ All on one node, NVLink communication
```

**Design**:
```
Topology Hierarchy:
  Region â†’ Zone â†’ Rack â†’ Node â†’ GPU
  
Scoring:
  Same node:       +100 points
  Same rack:       +50 points  
  Same zone:       +20 points
  Same region:     +5 points
  Different region: -50 points
```

**Implementation**:
```go
type TopologyScore struct {
    SameNode      int
    SameRack      int
    SameZone      int
    CrossRegion   int
}

func ScorePlacement(gpus []GPU) float64 {
    score := 0.0
    for i := 0; i < len(gpus)-1; i++ {
        for j := i+1; j < len(gpus); j++ {
            if gpus[i].Node == gpus[j].Node {
                score += 100
            } else if gpus[i].Rack == gpus[j].Rack {
                score += 50
            } else if gpus[i].Zone == gpus[j].Zone {
                score += 20
            }
            // etc.
        }
    }
    return score
}
```

---

#### #5: Priority & Preemption

**Purpose**: Allow high-priority workloads to preempt lower-priority jobs  
**Complexity**: Medium  
**Status**: âœ… Complete (MVP)  
**Dependencies**: #17 (Job Lifecycle Management)

**Problem**:
```
Production ML inference: CRITICAL (needs GPUs NOW)
Research experiment: LOW (can wait)

If all GPUs busy with research â†’ Inference waits â†’ BAD
```

**Solution - Priority Levels**:
```
Priority 0: CRITICAL    (production inference, urgent)
Priority 1: HIGH        (important training jobs)
Priority 2: NORMAL      (standard workloads)
Priority 3: LOW         (research, batch jobs)
Priority 4: BEST_EFFORT (can be killed anytime)
```

**Preemption Logic**:
```go
func CanPreempt(running Job, incoming Job) bool {
    // Can only preempt if priority gap â‰¥ 2
    priorityGap := running.Priority - incoming.Priority
    return priorityGap >= 2
}

func Preempt(victim Job) {
    // Graceful shutdown
    victim.SendSIGTERM()
    
    // Wait 30 seconds
    time.Sleep(30 * time.Second)
    
    // Force kill if still running
    if victim.IsRunning() {
        victim.SendSIGKILL()
    }
    
    // Checkpoint state (if supported)
    victim.Checkpoint()
}
```

---

#### #6: Exactly-Once Job Execution

**Purpose**: Guarantee no duplicate execution under retries/failures  
**Complexity**: High  
**Status**: âœ… Complete (MVP)  
**Dependencies**: #18, #19

**See**: [EXACTLY_ONCE.md](./EXACTLY_ONCE.md) for full design

**Three-Layer Defense**:
```
Layer 1: Request Deduplication (Redis)
  Same RequestID â†’ Same JobID
  
Layer 2: Distributed Leasing (etcd)
  Only one worker holds lease
  TTL-based expiration
  
Layer 3: Fencing Tokens (etcd)
  Monotonic counters prevent zombies
  Atomic compare-and-swap
```

**Guaranteed Properties**:
- âœ… No duplicates (job never executes >1 time)
- âœ… No lost executions (result persists)
- âœ… Convergence (recovers from any failure)

---

### Control Plane Design

These features handle global coordination, cluster management, and control plane architecture.

---

#### #7: Global Control Plane

**Purpose**: Central orchestrator coordinating per-cluster schedulers  
**Complexity**: High  
**Status**: â³ Planned (Phase 2)  
**Dependencies**: None (foundational)

**Design**:
```
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚ Global Control  â”‚
                  â”‚     Plane       â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                 â”‚                 â”‚
         â†“                 â†“                 â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  Cluster 1  â”‚   â”‚  Cluster 2  â”‚   â”‚  Cluster 3  â”‚
  â”‚  Scheduler  â”‚   â”‚  Scheduler  â”‚   â”‚  Scheduler  â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Responsibilities**:
- Accept job submissions (single entry point)
- Route jobs to appropriate cluster
- Track cluster health
- Global resource accounting
- SLA enforcement

**Implementation**:
```go
type GlobalScheduler struct {
    clusters map[string]*ClusterState
    jobQueue *JobQueue
    
    // Raft consensus for HA
    raft *raft.Raft
}

func (g *GlobalScheduler) SubmitJob(job Job) error {
    // 1. Validate job
    // 2. Choose cluster
    cluster := g.chooseCluster(job)
    
    // 3. Route to cluster scheduler
    return cluster.ScheduleJob(job)
}
```

---

#### #8: Cluster Autonomy

**Purpose**: Local failover control when global plane unreachable  
**Complexity**: Medium  
**Status**: â³ Planned (Phase 2)  
**Dependencies**: #7

**Problem**:
```
Global control plane crashes
         â†“
Clusters can't schedule new jobs
         â†“
Complete outage (BAD!)
```

**Solution - Autonomous Mode**:
```
1. Cluster detects global plane unreachable (heartbeat timeout)
2. Cluster switches to AUTONOMOUS mode
3. Cluster schedules jobs locally (with local queue)
4. When global plane returns:
   - Reconcile state
   - Resume normal mode
```

**Implementation**:
```go
type ClusterMode int

const (
    FEDERATED  ClusterMode = 0  // Normal: global control
    AUTONOMOUS ClusterMode = 1  // Failover: local control
)

func (c *ClusterScheduler) HeartbeatLoop() {
    for {
        if !c.global.IsReachable() {
            c.mode = AUTONOMOUS
            log.Warn("Global plane unreachable, switching to autonomous mode")
        } else if c.mode == AUTONOMOUS {
            c.mode = FEDERATED
            c.reconcileState()
        }
        time.Sleep(10 * time.Second)
    }
}
```

---

#### #9: Dynamic Cluster Registration

**Purpose**: Clusters join/leave federation dynamically  
**Complexity**: Medium  
**Status**: â³ Planned (Phase 3)  
**Dependencies**: #7, #8

**Design**:
```
New cluster comes online:
1. Cluster announces to global plane (etcd discovery)
2. Global plane validates cluster (health check)
3. Cluster added to routing table
4. Start receiving job assignments

Cluster goes offline:
1. Heartbeat timeout detected
2. Global plane marks cluster OFFLINE
3. Drain existing jobs (graceful shutdown)
4. Remove from routing table
```

---

#### #10: Health & Heartbeat Propagation

**Purpose**: Gossip-based or Raft-based health synchronization  
**Complexity**: Medium  
**Status**: â³ Planned (Phase 3)  
**Dependencies**: #7, #9

**Options**:

**Option A: Gossip Protocol** (like Consul)
```
Pros: Decentralized, scales to 1000s of nodes
Cons: Eventually consistent, complex debugging
```

**Option B: Raft Consensus** (like etcd)
```
Pros: Strong consistency, simpler reasoning
Cons: Limited to ~100 nodes, single leader bottleneck
```

**Likely choice**: Raft (simpler, good enough for <100 clusters)

---

#### #11: Eventual Consistency + Strong Convergence

**Purpose**: CRDTs or Raft for critical state  
**Complexity**: High  
**Status**: â³ Planned (Phase 3)  
**Dependencies**: #7, #10

**Design Decision**:
```
Metadata (cluster health, topology):
  â†’ Eventual consistency OK (CRDTs)
  â†’ Faster, scales better
  
Critical state (job assignments, leases):
  â†’ Strong consistency required (Raft)
  â†’ Prevents split-brain
```

---

#### #12: API Gateway / Custom API Server

**Purpose**: Unified global API for job submission  
**Complexity**: High  
**Status**: â³ Planned (Phase 3)  
**Dependencies**: #7

**Design**:
```
RESTful API:
  POST   /api/v1/jobs           â†’ Submit job
  GET    /api/v1/jobs/:id       â†’ Get job status
  DELETE /api/v1/jobs/:id       â†’ Cancel job
  GET    /api/v1/clusters       â†’ List clusters
  GET    /api/v1/clusters/:id   â†’ Get cluster state
```

---

### Resource Awareness

These features handle intelligent resource placement based on hardware topology.

---

#### #13: GPU-Aware Scheduling with Topology

**Purpose**: Match GPU count, model, NVLink, NUMA affinity  
**Complexity**: Medium-High  
**Status**: âœ… Complete (MVP - basic)  
**Dependencies**: None

**See**: [GPU_TOPOLOGY.md](./GPU_TOPOLOGY.md) for full design

**Key Capabilities**:
- Detect GPU count, model, memory
- Parse NVLink topology matrix
- Score placements (NVLink +50, PCIe -30)
- Choose optimal GPU subset

**Impact**: 3-5x training speedup

---

#### #14: NUMA / Memory Bandwidth Awareness

**Purpose**: Minimize cross-NUMA penalties  
**Complexity**: Medium-High  
**Status**: â³ Planned (Phase 2)  
**Dependencies**: #13

**Problem**:
```
NUMA Node 0: CPU 0-15, GPU 0-3, Memory 0-63GB
NUMA Node 1: CPU 16-31, GPU 4-7, Memory 64-127GB

Job allocated: GPU-0, CPU-20, Memory-70GB
  â†’ GPU on Node 0
  â†’ CPU on Node 1  
  â†’ Memory on Node 1
  â†’ Cross-NUMA traffic (slow!)
```

**Solution**:
```
Allocate resources from SAME NUMA node:
  GPU-0 â†’ CPU 0-15 â†’ Memory 0-63GB
  
Result: Local memory access, faster
```

---

#### #15: Network Bandwidth & Topology Awareness

**Purpose**: Factor latency/bandwidth into scheduling score  
**Complexity**: Medium-High  
**Status**: â³ Planned (Phase 3)  
**Dependencies**: #4

**Design**:
```
Network Topology:
  10 GbE switch:  Latency=0.5ms, BW=10Gbps
  40 GbE switch:  Latency=0.3ms, BW=40Gbps
  100 GbE switch: Latency=0.1ms, BW=100Gbps
  
Job requires high BW between nodes:
  â†’ Prefer 100 GbE connected nodes
```

---

#### #16: Heterogeneous Hardware Scheduling

**Purpose**: Support CPUs, GPUs, TPUs, FPGAs, custom accelerators  
**Complexity**: Medium  
**Status**: â³ Planned (Phase 2)  
**Dependencies**: #13

**Design**:
```go
type Accelerator interface {
    Type() string       // "GPU", "TPU", "FPGA"
    Model() string      // "V100", "TPUv4", "Xilinx"
    Memory() int64      // Bytes
    Supports(job Job) bool
}

func ScheduleHeterogeneous(job Job, resources []Accelerator) Accelerator {
    candidates := filterByRequirements(job, resources)
    return chooseBest(candidates)
}
```

---

### Job Execution & Reliability

These features handle job lifecycle, retries, and execution guarantees.

---

#### #17: Job Lifecycle Management

**Purpose**: State machine for job states (Pending â†’ Running â†’ Succeeded/Failed)  
**Complexity**: Low  
**Status**: âœ… Complete (MVP)  
**Dependencies**: None

**State Machine**:
```
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ PENDING â”‚
        â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
             â”‚ (worker acquires lease)
             â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ RUNNING â”‚
        â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
             â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
      â”‚             â”‚
      â†“             â†“
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚ SUCCEEDEDâ”‚  â”‚ FAILED  â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
                    â”‚ (retry if < maxRetries)
                    â†“
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚ RETRYING â”‚
               â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                    â”‚ (backoff delay)
                    â†“
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚ PENDING â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

#### #18: Idempotent Job Submission

**Purpose**: Client-side deduplication with request IDs  
**Complexity**: Medium  
**Status**: â³ Planned (Phase 2)  
**Dependencies**: None

**Design**:
```
Client generates RequestID (UUID)
Client submits job with RequestID
Scheduler checks Redis: "Did I see this RequestID before?"
  - YES: Return existing JobID (no-op)
  - NO: Create new job, cache RequestID â†’ JobID mapping
```

**Guarantees**:
- Same RequestID always returns same JobID
- No duplicate jobs created

---

#### #19: Distributed Locking / Lease System

**Purpose**: Lease-based coordination for exactly-once  
**Complexity**: Medium  
**Status**: âœ… Complete (MVP - implicit in #6)  
**Dependencies**: None

**Design**:
```go
type Lease struct {
    JobID        string
    WorkerID     string
    FencingToken int64
    TTL          int64  // seconds
    AcquiredAt   time.Time
}

func AcquireJobLease(jobID string, workerID string, ttl int) (*Lease, error) {
    // Atomic compare-and-swap
    lease := &Lease{
        JobID:    jobID,
        WorkerID: workerID,
        FencingToken: getNextToken(),  // Monotonic counter
        TTL:      ttl,
    }
    
    // Only succeeds if no existing lease
    success := etcd.CompareAndSwap("/leases/" + jobID, nil, lease)
    if !success {
        return nil, errors.New("lease already held")
    }
    
    return lease, nil
}
```

---

#### #20: Checkpointing & Recovery

**Purpose**: Mid-job state persistence for fault recovery  
**Complexity**: High  
**Status**: â³ Planned (Phase 3)  
**Dependencies**: #17, #21

**Design**:
```
Long-running job (10 hours):
  Checkpoint every 30 minutes
  Save model weights, optimizer state to S3
  
Job crashes at hour 5:
  Resume from last checkpoint (hour 4.5)
  Lost work: 30 minutes (not 5 hours!)
```

---

#### #21: Backoff & Retry Policy

**Purpose**: Exponential backoff with jitter, SLA-aware  
**Complexity**: Medium  
**Status**: âœ… Complete (MVP)  
**Dependencies**: #17

**Formula**:
```
backoff = min(initialBackoff * multiplier^attempt, maxBackoff)
backoff += random(-25%, +25%)  // Jitter

Example:
  Attempt 1: 1s + jitter â†’ 1.2s
  Attempt 2: 2s + jitter â†’ 1.8s
  Attempt 3: 4s + jitter â†’ 4.3s
  Attempt 4: 8s + jitter â†’ 7.6s
```

**Prevents**: Thundering herd, retry storms

---

### Observability & Security

These features provide visibility, monitoring, and access control.

---

#### #22: Global Metrics Pipeline

**Purpose**: Prometheus + OpenTelemetry federation  
**Complexity**: Medium  
**Status**: âœ… Complete (MVP)  
**Dependencies**: None

**Architecture**:
```
Worker â†’ Prometheus scrape
         â†“
    Push to global aggregator
         â†“
    Long-term storage (Thanos/Cortex)
         â†“
    Query via Grafana
```

**Metrics Exposed**:
- `ares_jobs_total{state="running|succeeded|failed"}`
- `ares_gpu_utilization{gpu_id="0"}`
- `ares_scheduling_latency_seconds`
- `ares_lease_acquisitions_total`

---

#### #23: Unified Dashboard & Tracing

**Purpose**: Grafana + Jaeger/Tempo for traces  
**Complexity**: Low-Medium  
**Status**: âœ… Complete (MVP)  
**Dependencies**: #22

**Features**:
- Real-time job queue view
- GPU utilization heatmap
- Cluster health overview
- Distributed traces (OpenTelemetry)

---

#### #24: Cluster & Job Health Dashboard

**Purpose**: Real-time view of job latency, failure rate, utilization  
**Complexity**: Low-Medium  
**Status**: âœ… Complete (MVP)  
**Dependencies**: #22, #23

**Panels**:
- Jobs/sec (last 5 minutes)
- Failure rate (%)
- P50/P95/P99 scheduling latency
- GPU utilization by cluster
- Retry rate

---

#### #25: RBAC + Tenant Isolation

**Purpose**: Namespace/tenant-level quota and policy enforcement  
**Complexity**: Medium  
**Status**: â³ Planned (Phase 2)  
**Dependencies**: #3

**Design**:
```
Tenant A:
  - Max GPUs: 10
  - Max jobs: 100
  - Priority: NORMAL
  
Tenant B:
  - Max GPUs: 50
  - Max jobs: 500
  - Priority: HIGH
  
Enforce quotas at submission time
```

---

#### #26: Audit Logging & Policy Validation

**Purpose**: All job/API actions logged and validated centrally  
**Complexity**: Medium  
**Status**: â³ Planned (Phase 3)  
**Dependencies**: #12

**Design**:
```
Audit log entry:
{
  "timestamp": "2025-01-15T10:30:00Z",
  "action": "SUBMIT_JOB",
  "user": "alice@nyu.edu",
  "job_id": "abc-123",
  "cluster": "us-west-1",
  "status": "SUCCESS"
}
```

---

## Polaris Features

Polaris is the **observability platform** purpose-built for Ares. It extends Ares' basic metrics (#22-24) with advanced SLA tracking, anomaly detection, and operational insights.

---

### #22 (Polaris): Global Metrics Pipeline

**Status**: âœ… Complete (basic), ğŸš§ Enhanced version in progress  
**Dependencies**: Ares #22

**Polaris Enhancements**:
- Federated Prometheus across all clusters
- Long-term storage (Thanos/Cortex)
- Cross-cluster metric aggregation
- Custom SLA metrics

**Design**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Cluster 1 â”‚   â”‚Cluster 2 â”‚   â”‚Cluster 3 â”‚
â”‚Prometheusâ”‚   â”‚Prometheusâ”‚   â”‚Prometheusâ”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
      â”‚              â”‚              â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Polaris Global â”‚
            â”‚  Aggregator    â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Thanos Storage â”‚
            â”‚  (Long-term)   â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Metrics**:
- Standard Ares metrics (jobs, latency, GPU utilization)
- **NEW**: Cross-cluster correlation
- **NEW**: SLA compliance rate
- **NEW**: Cost per job (compute time Ã— GPU cost)

---

### #23 (Polaris): Unified Dashboard & Tracing

**Status**: âœ… Complete (basic), ğŸš§ Enhanced version in progress  
**Dependencies**: Ares #22, #23

**Polaris Enhancements**:
- Distributed tracing across clusters (Jaeger/Tempo)
- End-to-end job latency visualization
- Anomaly detection (ML-based)
- Cost dashboards

**Example Trace**:
```
Job abc-123 end-to-end latency: 145ms

Span 1: Client submit          â†’ 5ms
Span 2: Global scheduler route â†’ 10ms
Span 3: Cluster-1 queue        â†’ 20ms
Span 4: GPU placement scoring  â†’ 15ms
Span 5: Worker lease acquire   â†’ 50ms
Span 6: Job execution          â†’ 40ms
Span 7: Result commit          â†’ 5ms
```

---

### #24 (Polaris): Cluster & Job Health Dashboard

**Status**: âœ… Complete (basic), ğŸš§ Enhanced version in progress  
**Dependencies**: Ares #22-24

**Polaris Enhancements**:
- **SLA Compliance Tracking**
    - Jobs meeting SLA deadline (%)
    - P95/P99 latency vs SLA target
    - SLA violations by cluster

- **Anomaly Detection**
    - Sudden failure rate spike (alert)
    - GPU utilization drop (alert)
    - Scheduling latency outliers

- **Predictive Insights**
    - "Cluster-2 will hit capacity in 2 hours"
    - "Job queue backlog growing, scale up?"

**Dashboard Panels**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SLA Compliance (Last 24h)                   â”‚
â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘ 92% (target: 95%)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Cluster Health Heatmap                      â”‚
â”‚ Cluster-1: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 95% healthy     â”‚
â”‚ Cluster-2: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘ 60% healthy âš ï¸  â”‚
â”‚ Cluster-3: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 100% healthy âœ… â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### #26 (Polaris): Audit Logging & Policy Validation

**Status**: â³ Planned (Phase 3)  
**Dependencies**: Ares #12, #26

**Polaris Enhancements**:
- Centralized audit log aggregation
- Policy violation detection
- Security event correlation
- Compliance reporting

**Example Policy**:
```yaml
policy:
  name: "GPU usage quota"
  rule: "tenant.gpu_hours < tenant.quota"
  action: "REJECT_JOB"
  alert: "Email admin + Slack #alerts"
```

---

## Implementation Roadmap

### Phase 1: MVP (Nov 2 - Dec 8, 2025) âœ… 27% Complete

**Completed Features (7)**:
- #3: Fair Resource Allocation
- #4: Topology-Aware Scheduling (basic)
- #5: Priority & Preemption
- #6: Exactly-Once Job Execution
- #13: GPU-Aware Scheduling (basic)
- #17: Job Lifecycle Management
- #21: Backoff & Retry Policy

**In Progress (2)**:
- #22: Global Metrics Pipeline (basic)
- #23: Unified Dashboard (basic)

**Timeline**: 36 days, sustainable pace

---

### Phase 2: Core Features (Jan - Feb 2026) â†’ 54% Complete

**Features to Add (7)**:
- #1: Multi-Cluster Scheduling (basic)
- #7: Global Control Plane
- #8: Cluster Autonomy
- #14: NUMA Awareness
- #16: Heterogeneous Hardware
- #18: Idempotent Job Submission
- #25: RBAC + Tenant Isolation

**Focus**: Production-grade reliability + observability

**Timeline**: 8 weeks while interviewing

---

### Phase 3: Advanced Features (Mar - June 2026) â†’ 85% Complete

**Features to Add (9)**:
- #2: Multi-Region Federation
- #9: Dynamic Cluster Registration
- #10: Health & Heartbeat Propagation
- #11: Eventual Consistency
- #12: API Gateway
- #15: Network Bandwidth Awareness
- #20: Checkpointing & Recovery
- #24: Enhanced Polaris Dashboard
- #26: Audit Logging

**Focus**: Scale, federation, advanced ops

**Timeline**: 4 months while working at job

---

### Phase 4: Full Vision (July - Dec 2026) â†’ 100% Complete

**Polish & Community**:
- Documentation improvements
- Performance optimization
- Community contributions
- Conference talks
- Production deployments

**Timeline**: 6 months

---

## Feature Dependencies

### Dependency Graph

```
#17 (Job Lifecycle) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â†’ #5 (Priority)
                             â”‚
                             â””â”€â”€â†’ #21 (Retry Policy)
                                   â”‚
                                   â””â”€â”€â†’ #20 (Checkpointing)

#18 (Idempotency) â”€â”€â”€â”
#19 (Leasing) â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â†’ #6 (Exactly-Once)
                     â”‚
                     
#13 (GPU-Aware) â”€â”€â”€â”€â”€â”¼â”€â”€â†’ #4 (Topology-Aware)
                     â”‚         â”‚
                     â”‚         â””â”€â”€â†’ #15 (Network Awareness)
                     â”‚
                     â””â”€â”€â†’ #14 (NUMA Awareness)
                     
                     â””â”€â”€â†’ #16 (Heterogeneous)

#7 (Global Plane) â”€â”€â”€â”¬â”€â”€â†’ #1 (Multi-Cluster)
                     â”‚         â”‚
                     â”‚         â””â”€â”€â†’ #2 (Multi-Region)
                     â”‚
                     â”œâ”€â”€â†’ #8 (Autonomy)
                     â”‚
                     â”œâ”€â”€â†’ #9 (Dynamic Registration)
                     â”‚
                     â”œâ”€â”€â†’ #10 (Heartbeat)
                     â”‚
                     â”œâ”€â”€â†’ #11 (Consistency)
                     â”‚
                     â””â”€â”€â†’ #12 (API Gateway)

#22 (Metrics) â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â†’ #23 (Dashboard)
                     â”‚
                     â””â”€â”€â†’ #24 (Health Dashboard)

#3 (Fairness) â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â†’ #25 (RBAC)

#12 (API Gateway) â”€â”€â”€â”¼â”€â”€â†’ #26 (Audit Logging)
```

### Critical Path

```
To reach Multi-Cluster (#1):
  Requires: #7 (Global Control Plane)
  
To reach Multi-Region (#2):
  Requires: #1, #7, #8, #9
  
To reach Exactly-Once (#6):
  Requires: #18, #19
  
To reach Full Production:
  Requires: All Phase 2 features + observability
```

---

## Summary

**Total Features**: 26 (22 Ares + 4 Polaris)  
**Completed**: 7 (27%)  
**Current Focus**: Multi-cluster + observability (Week 4)  
**Next Milestone**: 14 features by Feb 2026 (54%)  
**Full Vision**: 26 features by Dec 2026 (100%)

This feature matrix serves as both:
1. **Technical specification** for implementation
2. **Roadmap** for development phases
3. **Portfolio artifact** demonstrating distributed systems depth

Each feature is designed to showcase specific distributed systems patterns (consensus, leasing, topology awareness, SLA enforcement) at L4/L5 engineering level.

---

**Last Updated**: December 2025  
**Maintained By**: Sathya Balasubramani ([@BITS08SATHYA](https://github.com/BITS08SATHYA))